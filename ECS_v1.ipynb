{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fitz  # PyMuPDF\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Step 1: Read PDF Content\n",
    "def read_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Step 2: Load Llama 2 model\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Example model name, adjust based on your needs\n",
    "model_name = \"distilbert-base-uncased-distilled-squad\" \n",
    "question_answerer = pipeline(\"question-answering\", model=model_name)\n",
    "\n",
    "# Step 3: Function to ask questions\n",
    "def ask_question(context, question):\n",
    "    return question_answerer(question=question, context=context)\n",
    "\n",
    "# E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: AI\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_text = read_pdf(\"meta23q1.pdf\")  # Replace with your PDF file path\n",
    "question = \"What is the main topic of the document?\"  # Example question\n",
    "answer = ask_question(pdf_text, question)\n",
    "\n",
    "print(\"Answer:\", answer['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Mark Zuckerberg\n"
     ]
    }
   ],
   "source": [
    "question= 'Who si the CEO of Meta?'\n",
    "answer = ask_question(pdf_text, question)\n",
    "\n",
    "\n",
    "print(\"Answer:\", answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Deborah Crawford\n"
     ]
    }
   ],
   "source": [
    "question= 'Who si the CFO of Meta?'\n",
    "answer = ask_question(pdf_text, question)\n",
    "\n",
    "\n",
    "print(\"Answer:\", answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarizer= pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# PINECONE_API_ENV = os.getenv(\"PINECONE_API_ENV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(openai.api_key)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "# Use a pipeline as a high-level helper\n",
    "# from transformers imposrt pipeline\n",
    "\n",
    "\n",
    "# Step 1: Read PDF Content\n",
    "def read_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_text = read_pdf(\"chat_earningcall/NateraQ423.pdf\")  # Replace with your PDF file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35009"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 500\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# df = pd.read_csv(\"text.csv\", index_col=0)\n",
    "# df[\"tokens\"] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "pdf_token= tokenizer.encode(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7569"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_many(text, max_tokens):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "        \n",
    "    # Add the last chunk to the list of chunks\n",
    "    if chunk:\n",
    "        chunks.append(\". \".join(chunk) + \".\")\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= split_into_many(pdf_text, 500)\n",
    "\n",
    "# data = []\n",
    "# for row in df.iterrows():\n",
    "#     title = row[1][\"title\"]\n",
    "#     url = row[1][\"url\"]\n",
    "#     text = row[1][\"text\"]\n",
    "#     tokens = row[1][\"tokens\"]\n",
    "\n",
    "#     if tokens <= MAX_TOKENS:\n",
    "#         data.append((title, url, text))\n",
    "#     else:\n",
    "#         for chunk in split_into_many(text, MAX_TOKENS):\n",
    "#             data.append((title, url, chunk))\n",
    "\n",
    "# df = pd.DataFrame(data, columns=[\"title\", \"url\", \"text\"])\n",
    "# df[\"tokens\"] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2762877218.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for chunk in df: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(data, columns= ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token']=df.text.apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Participants \\nMichael Brophy - Chief ...</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nWe caution you that such statements reflect ...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nGross margins in Q4 came in at 51.4%, compar...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We'll be talking today about some big first of...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the year ended, we saw an \\nacceleration of...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nIn addition, we've also got a number of pote...</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nAnd on the Ravgen trial, we were found to no...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When we run our test, we're using our core SNP...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nSo in addition to our existing portfolio, we...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nMoving on to the pedal trial with over 500 p...</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nNow, I want to hand the call over to Alex to...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If the study is positive, \\nwe expect it to be...</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nOvarian cancer affects close to 20,000 women...</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Revenues were up 43% and gross margins expande...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nWhile there are a lot of variables that will...</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>And I'm looking forward to sharing our progres...</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  token\n",
       "0   Company Participants \\nMichael Brophy - Chief ...    480\n",
       "1   \\nWe caution you that such statements reflect ...    475\n",
       "2   \\nGross margins in Q4 came in at 51.4%, compar...    475\n",
       "3   We'll be talking today about some big first of...    477\n",
       "4   As the year ended, we saw an \\nacceleration of...    475\n",
       "5   \\nIn addition, we've also got a number of pote...    451\n",
       "6   \\nAnd on the Ravgen trial, we were found to no...    497\n",
       "7   When we run our test, we're using our core SNP...    500\n",
       "8   \\nSo in addition to our existing portfolio, we...    484\n",
       "9   \\nMoving on to the pedal trial with over 500 p...    486\n",
       "10  \\nNow, I want to hand the call over to Alex to...    484\n",
       "11  If the study is positive, \\nwe expect it to be...    501\n",
       "12  \\nOvarian cancer affects close to 20,000 women...    501\n",
       "13  Revenues were up 43% and gross margins expande...    461\n",
       "14  \\nWhile there are a lot of variables that will...    487\n",
       "15  And I'm looking forward to sharing our progres...    336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_ENGINE = \"text-embedding-ada-002\"\n",
    "\n",
    "# df[\"embeddings\"] = df.text.apply(\n",
    "#     lambda x: client.embeddings.create(input=x, engine=EMBEDDING_ENGINE)[\"data\"][0][\n",
    "#         \"embedding\"\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "embeddings = []\n",
    "for t in df.text:\n",
    "    response=client.embeddings.create(input=t, model=EMBEDDING_ENGINE)\n",
    "    for i, be in enumerate(response.data):\n",
    "        assert i==be.index\n",
    "    emb= [e.embedding for e in response.data]\n",
    "    embeddings.extend(emb)\n",
    "\n",
    "#t= client.embeddings.create(input=data[0], model=EMBEDDING_ENGINE)\n",
    "# df.to_csv(\"embeddings.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame({'text':df.text, 'embedding':embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company Participants \\nMichael Brophy - Chief ...</td>\n",
       "      <td>[-0.013012096285820007, -0.018484851345419884,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nWe caution you that such statements reflect ...</td>\n",
       "      <td>[-0.01779131032526493, -0.021527621895074844, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nGross margins in Q4 came in at 51.4%, compar...</td>\n",
       "      <td>[-0.012778418138623238, -0.0076899658888578415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We'll be talking today about some big first of...</td>\n",
       "      <td>[-0.011258041486144066, -0.01653985120356083, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the year ended, we saw an \\nacceleration of...</td>\n",
       "      <td>[-0.016132786870002747, -0.02123400755226612, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nIn addition, we've also got a number of pote...</td>\n",
       "      <td>[-0.020121315494179726, -0.02366803027689457, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nAnd on the Ravgen trial, we were found to no...</td>\n",
       "      <td>[-0.018266690894961357, -0.014103163965046406,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When we run our test, we're using our core SNP...</td>\n",
       "      <td>[-0.022130317986011505, 0.005415887106209993, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nSo in addition to our existing portfolio, we...</td>\n",
       "      <td>[-0.007602710276842117, -0.006420145742595196,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nMoving on to the pedal trial with over 500 p...</td>\n",
       "      <td>[-0.0028660634998232126, -0.02936878427863121,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nNow, I want to hand the call over to Alex to...</td>\n",
       "      <td>[-0.007191954646259546, 0.007551552727818489, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If the study is positive, \\nwe expect it to be...</td>\n",
       "      <td>[-0.015930218622088432, -0.014648477546870708,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nOvarian cancer affects close to 20,000 women...</td>\n",
       "      <td>[-0.01321981381624937, -0.03131227195262909, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Revenues were up 43% and gross margins expande...</td>\n",
       "      <td>[-0.004698917735368013, -0.009759807027876377,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nWhile there are a lot of variables that will...</td>\n",
       "      <td>[-0.015061188489198685, -0.016248412430286407,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>And I'm looking forward to sharing our progres...</td>\n",
       "      <td>[0.0010503527009859681, -0.019411277025938034,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Company Participants \\nMichael Brophy - Chief ...   \n",
       "1   \\nWe caution you that such statements reflect ...   \n",
       "2   \\nGross margins in Q4 came in at 51.4%, compar...   \n",
       "3   We'll be talking today about some big first of...   \n",
       "4   As the year ended, we saw an \\nacceleration of...   \n",
       "5   \\nIn addition, we've also got a number of pote...   \n",
       "6   \\nAnd on the Ravgen trial, we were found to no...   \n",
       "7   When we run our test, we're using our core SNP...   \n",
       "8   \\nSo in addition to our existing portfolio, we...   \n",
       "9   \\nMoving on to the pedal trial with over 500 p...   \n",
       "10  \\nNow, I want to hand the call over to Alex to...   \n",
       "11  If the study is positive, \\nwe expect it to be...   \n",
       "12  \\nOvarian cancer affects close to 20,000 women...   \n",
       "13  Revenues were up 43% and gross margins expande...   \n",
       "14  \\nWhile there are a lot of variables that will...   \n",
       "15  And I'm looking forward to sharing our progres...   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.013012096285820007, -0.018484851345419884,...  \n",
       "1   [-0.01779131032526493, -0.021527621895074844, ...  \n",
       "2   [-0.012778418138623238, -0.0076899658888578415...  \n",
       "3   [-0.011258041486144066, -0.01653985120356083, ...  \n",
       "4   [-0.016132786870002747, -0.02123400755226612, ...  \n",
       "5   [-0.020121315494179726, -0.02366803027689457, ...  \n",
       "6   [-0.018266690894961357, -0.014103163965046406,...  \n",
       "7   [-0.022130317986011505, 0.005415887106209993, ...  \n",
       "8   [-0.007602710276842117, -0.006420145742595196,...  \n",
       "9   [-0.0028660634998232126, -0.02936878427863121,...  \n",
       "10  [-0.007191954646259546, 0.007551552727818489, ...  \n",
       "11  [-0.015930218622088432, -0.014648477546870708,...  \n",
       "12  [-0.01321981381624937, -0.03131227195262909, 0...  \n",
       "13  [-0.004698917735368013, -0.009759807027876377,...  \n",
       "14  [-0.015061188489198685, -0.016248412430286407,...  \n",
       "15  [0.0010503527009859681, -0.019411277025938034,...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_nav",
   "language": "python",
   "name": "llm_nav"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
